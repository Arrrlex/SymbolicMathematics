{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(Path('..').resolve())\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from symbolicmathematics.utils import load_settings, to_cuda\n",
    "from symbolicmathematics.envs import build_env\n",
    "from symbolicmathematics.envs.sympy_utils import simplify\n",
    "from symbolicmathematics.model import build_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build environment / Reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model, e.g. \"wget https://dl.fbaipublicfiles.com/SymbolicMathematics/models/fwd_bwd.pth\"\n",
    "cpu = True\n",
    "model_name = 'fwd_bwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_settings(cpu=cpu, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = build_env(params)\n",
    "x = env.local_dict['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = build_modules(env, params)\n",
    "encoder = modules['encoder']\n",
    "decoder = modules['decoder']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from a function F, compute its derivative f = F', and try to recover F from f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can modify the integral function the model has to predict, F\n",
    "F_infix = 'x * tan(exp(x)/x)'\n",
    "# F_infix = 'x * cos(x**2) * tan(x)'\n",
    "# F_infix = 'cos(x**2 * exp(x * cos(x)))'\n",
    "# F_infix = 'ln(cos(x + exp(x)) * sin(x**2 + 2) * exp(x) / x)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F (integral, that the model will try to predict)\n",
    "F = sp.S(F_infix, locals=env.local_dict)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f (F', that the model will take as input)\n",
    "f = F.diff(x)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute prefix representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F_prefix = env.sympy_to_prefix(F)\n",
    "f_prefix = env.sympy_to_prefix(f)\n",
    "print(f\"F prefix: {' '.join(F_prefix)}\")\n",
    "print(f\"f prefix: {' '.join(f_prefix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_prefix = env.clean_prefix(['sub', 'derivative', 'f', 'x', 'x'] + f_prefix)\n",
    "x1 = torch.LongTensor(\n",
    "    [env.eos_index] +\n",
    "    [env.word2id[w] for w in x1_prefix] +\n",
    "    [env.eos_index]\n",
    ").view(-1, 1)\n",
    "len1 = torch.LongTensor([len(x1)])\n",
    "x1, len1 = to_cuda([x1, len1], cpu=params.cpu)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded = encoder('fwd', x=x1, lengths=len1, causal=False).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode with beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 10\n",
    "with torch.no_grad():\n",
    "    _, _, beam = decoder.generate_beam(encoded, len1, beam_size=beam_size, length_penalty=1.0, early_stopping=1, max_len=200)\n",
    "    assert len(beam) == 1\n",
    "hypotheses = beam[0].hyp\n",
    "assert len(hypotheses) == beam_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Input function f: {f}\")\n",
    "print(f\"Reference function F: {F}\")\n",
    "print()\n",
    "\n",
    "for score, sent in sorted(hypotheses, key=lambda x: x[0], reverse=True):\n",
    "\n",
    "    # parse decoded hypothesis\n",
    "    ids = sent[1:].tolist()                  # decoded token IDs\n",
    "    tok = [env.id2word[wid] for wid in ids]  # convert to prefix\n",
    "\n",
    "    try:\n",
    "        hyp = env.prefix_to_infix(tok)       # convert to infix\n",
    "        hyp = env.infix_to_sympy(hyp)        # convert to SymPy\n",
    "\n",
    "        # check whether we recover f if we differentiate the hypothesis\n",
    "        # note that sometimes, SymPy fails to show that hyp' - f == 0, and \n",
    "        # the result is considered as invalid, although it may be correct\n",
    "        res = \"OK\" if simplify(hyp.diff(x) - f, seconds=1) == 0 else \"NO\"\n",
    "\n",
    "    except:\n",
    "        res = \"INVALID PREFIX EXPRESSION\"\n",
    "        hyp = tok\n",
    "\n",
    "    # print result\n",
    "    print(f\"{score:.5f}  {res}  {hyp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
